{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeef66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ---------------- Conditional VAE ----------------\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,\n",
    "                 loc_channels: int = 2,\n",
    "                 mask_channels: int = 1,\n",
    "                 latent_dim: int = 16,\n",
    "                 hidden_dims: List[int] = [32, 64, 128, 256],\n",
    "                 img_size: int = 40,\n",
    "                 coord_decode: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.in_channels = in_channels\n",
    "        self.loc_channels = loc_channels\n",
    "        self.mask_channels = mask_channels\n",
    "        self.coord_decode = coord_decode\n",
    "\n",
    "        # ---------------- Encoder ----------------\n",
    "        enc_in_channels = in_channels + loc_channels + mask_channels\n",
    "        self.hidden_dims_enc = hidden_dims\n",
    "        modules = []\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(enc_in_channels, h_dim, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU()\n",
    "                )\n",
    "            )\n",
    "            enc_in_channels = h_dim\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        # Compute encoder output sizes dynamically\n",
    "        encoder_sizes = self.compute_encoder_sizes(img_size, hidden_dims)\n",
    "        self.final_spatial = encoder_sizes[-1]\n",
    "        flat_size = hidden_dims[-1] * self.final_spatial**2\n",
    "\n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(flat_size, latent_dim)\n",
    "        self.fc_var = nn.Linear(flat_size, latent_dim)\n",
    "\n",
    "        # ---------------- CNN Decoder (optional) ----------------\n",
    "        if not coord_decode:\n",
    "            self.decoder_input = nn.Linear(\n",
    "                latent_dim + (loc_channels + mask_channels) * img_size * img_size,\n",
    "                flat_size\n",
    "            )\n",
    "            self.hidden_dims_dec = hidden_dims[::-1]\n",
    "            dec_modules = []\n",
    "            for i in range(len(self.hidden_dims_dec)-1):\n",
    "                dec_modules.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.ConvTranspose2d(\n",
    "                            self.hidden_dims_dec[i],\n",
    "                            self.hidden_dims_dec[i+1],\n",
    "                            kernel_size=3,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                            output_padding=0\n",
    "                        ),\n",
    "                        nn.BatchNorm2d(self.hidden_dims_dec[i+1]),\n",
    "                        nn.LeakyReLU()\n",
    "                    )\n",
    "                )\n",
    "            self.decoder = nn.Sequential(*dec_modules)\n",
    "            self.final_mu = nn.Conv2d(self.hidden_dims_dec[-1], out_channels=in_channels, kernel_size=3, padding=1)\n",
    "            self.final_logvar = nn.Conv2d(self.hidden_dims_dec[-1], out_channels=in_channels, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            # ---------------- Coordinate-based decoder ----------------\n",
    "            self.coord_mlp = nn.Sequential(\n",
    "                nn.Linear(latent_dim + 2, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 2)  # predict mu and logvar\n",
    "            )\n",
    "\n",
    "    # ---------------- Static methods ----------------\n",
    "    @staticmethod\n",
    "    def compute_encoder_sizes(img_size, hidden_dims, kernel_size=3, stride=2, padding=1):\n",
    "        sizes = []\n",
    "        size = img_size\n",
    "        for _ in hidden_dims:\n",
    "            size = (size + 2*padding - kernel_size) // stride + 1\n",
    "            sizes.append(size)\n",
    "        return sizes\n",
    "\n",
    "    # ---------------- Forward methods ----------------\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        result = self.encoder(x)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def decode(self, z: torch.Tensor, loc_mask: torch.Tensor = None, meas_mask: torch.Tensor = None,\n",
    "               coords: torch.Tensor = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        if self.coord_decode:\n",
    "            # coords shape: [B, N_points, 2], z: [B, latent_dim]\n",
    "            B, N, _ = coords.shape\n",
    "            z_exp = z.unsqueeze(1).repeat(1, N, 1)  # [B, N, latent_dim]\n",
    "            mlp_input = torch.cat([z_exp, coords], dim=-1)  # [B, N, latent+2]\n",
    "            out = self.coord_mlp(mlp_input)  # [B, N, 2]\n",
    "            mu_pred = out[..., 0:1]\n",
    "            logvar_pred = out[..., 1:2]\n",
    "            return mu_pred, logvar_pred\n",
    "        else:\n",
    "            # CNN decode (full grid)\n",
    "            cond = torch.cat([loc_mask, meas_mask], dim=1)\n",
    "            cond_flat = cond.view(cond.size(0), -1)\n",
    "            dec_input = torch.cat([z, cond_flat], dim=1)\n",
    "            result = self.decoder_input(dec_input)\n",
    "            result = result.view(-1, self.hidden_dims_dec[0], self.final_spatial, self.final_spatial)\n",
    "            result = self.decoder(result)\n",
    "\n",
    "            # Zero-pad to img_size\n",
    "            _, _, h, w = result.shape\n",
    "            pad_h = self.img_size - h\n",
    "            pad_w = self.img_size - w\n",
    "            if pad_h > 0 or pad_w > 0:\n",
    "                result = F.pad(result, (0, pad_w, 0, pad_h))\n",
    "\n",
    "            mu_pred = self.final_mu(result)\n",
    "            logvar_pred = torch.clamp(self.final_logvar(result), -10, 10)\n",
    "            return mu_pred, logvar_pred\n",
    "\n",
    "    def forward(self, x: torch.Tensor, loc_mask: torch.Tensor = None, meas_mask: torch.Tensor = None,\n",
    "                coords: torch.Tensor = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Tile location mask if needed\n",
    "        if loc_mask is not None and loc_mask.dim() == 3:\n",
    "            loc_mask = loc_mask.unsqueeze(0).repeat(x.size(0), 1, 1, 1)\n",
    "\n",
    "        enc_in = x\n",
    "        if loc_mask is not None and meas_mask is not None:\n",
    "            enc_in = torch.cat([x, loc_mask, meas_mask], dim=1)\n",
    "\n",
    "        mu, log_var = self.encode(enc_in)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        mu_pred, logvar_pred = self.decode(z, loc_mask, meas_mask, coords)\n",
    "        return mu_pred, logvar_pred, mu, log_var\n",
    "\n",
    "    # ---------------- Loss function ----------------\n",
    "    def loss_function(self, x: torch.Tensor, mu_pred: torch.Tensor, logvar_pred: torch.Tensor,\n",
    "                      mu: torch.Tensor, log_var: torch.Tensor, meas_mask: torch.Tensor = None,\n",
    "                      kld_weight: float = 1e-3) -> dict:\n",
    "        const = torch.log(torch.tensor(2.0 * torch.pi, device=x.device))\n",
    "        recon_var = torch.exp(logvar_pred)\n",
    "        nll_element = 0.5 * ((x - mu_pred)**2 / recon_var + logvar_pred + const)\n",
    "\n",
    "        if meas_mask is not None:\n",
    "            # mask over valid measurements\n",
    "            valid_mask = meas_mask.bool()\n",
    "            nll_element = nll_element * valid_mask\n",
    "            nll_loss = torch.mean(torch.sum(nll_element, dim=list(range(1, nll_element.dim()))) /\n",
    "                                  (valid_mask.sum(dim=list(range(1, valid_mask.dim()))) + 1e-8))\n",
    "        else:\n",
    "            nll_loss = torch.mean(torch.sum(nll_element, dim=list(range(1, nll_element.dim()))))\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim=1))\n",
    "        total_loss = nll_loss + kld_weight * kld_loss\n",
    "        return {\"loss\": total_loss, \"NLL\": nll_loss, \"KLD\": kld_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Define constants\n",
    "# -----------------------------\n",
    "H, W = 40, 40\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Load SINR measurements\n",
    "# -----------------------------\n",
    "df_dataset = pd.read_csv('combined_sinr.csv')  # 30 sensors\n",
    "sinr_cols = [col for col in df_dataset.columns if col.startswith('SINR_')]\n",
    "N = len(sinr_cols)\n",
    "num_samples = df_dataset.shape[0]\n",
    "print(f\"Loaded SINR data: {num_samples} samples, {N} sensor columns\")\n",
    "\n",
    "sinr_data = df_dataset[sinr_cols].to_numpy()  # (num_samples, 30)\n",
    "sinr_data_transposed = sinr_data.T  # (30, num_samples)\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Load location grid\n",
    "# -----------------------------\n",
    "df_grid = pd.read_csv('original_1600_grid_points.csv')  # 40x40 grid\n",
    "y_values = df_grid['y'].to_numpy()\n",
    "x_values = df_grid['x'].to_numpy()\n",
    "location_values = np.stack([y_values, x_values], axis=-1).reshape(H, W, 2)\n",
    "loc_mask_base = torch.tensor(location_values, dtype=torch.float32).permute(2, 0, 1)  # (2, H, W)\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Load sensor mask\n",
    "# -----------------------------\n",
    "df_mask = pd.read_csv('mask.csv')  # 1600 rows\n",
    "FLAG_COL = 'mask'\n",
    "boolean_sensor_mask = (df_mask[FLAG_COL] == 1).to_numpy()  # (1600,)\n",
    "num_sensors_from_mask = boolean_sensor_mask.sum()\n",
    "print(f\"Number of measured sensors from mask: {num_sensors_from_mask}\")\n",
    "\n",
    "# Map 1D mask to 2D grid indices\n",
    "all_y_pixel_indices = np.arange(H * W) // W\n",
    "all_x_pixel_indices = np.arange(H * W) % W\n",
    "train_coords_y = torch.tensor(all_y_pixel_indices[boolean_sensor_mask], dtype=torch.long)\n",
    "train_coords_x = torch.tensor(all_x_pixel_indices[boolean_sensor_mask], dtype=torch.long)\n",
    "num_train_locs = len(train_coords_y)\n",
    "print(f\"Number of training coordinates: {num_train_locs}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ Build dataset images\n",
    "# -----------------------------\n",
    "dataset_images = np.zeros((N, H, W), dtype=np.float32)\n",
    "for i in range(N):\n",
    "    sample_values = sinr_data_transposed[:, i]  # (30,)\n",
    "    dataset_images[i, train_coords_y, train_coords_x] = sample_values\n",
    "\n",
    "dataset_images = torch.tensor(dataset_images, dtype=torch.float32)  # (N, H, W)\n",
    "sensor_mask = dataset_images != 0  # boolean mask of measured points\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ Normalize sensor values only\n",
    "# -----------------------------\n",
    "sensor_vals = dataset_images[sensor_mask]\n",
    "mean = sensor_vals.mean()\n",
    "std = sensor_vals.std()\n",
    "dataset_norm = torch.zeros_like(dataset_images)\n",
    "dataset_norm[sensor_mask] = (dataset_images[sensor_mask] - mean) / (std + 1e-6)\n",
    "X_data = dataset_norm.unsqueeze(1)  # (N, 1, H, W)\n",
    "global_normalization_mean = mean\n",
    "global_normalization_std = std\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ Load valid coordinates CSV\n",
    "# -----------------------------\n",
    "df_valid_coords = pd.read_csv('valid_coords.csv')  # columns: y, x\n",
    "valid_coords = torch.tensor(df_valid_coords[['y','x']].to_numpy(), dtype=torch.long)  # (num_valid, 2)\n",
    "\n",
    "# -----------------------------\n",
    "# 8Ô∏è‚É£ Define k-sampling parameters\n",
    "# -----------------------------\n",
    "# You said you'll define these\n",
    "k_choices = torch.tensor([5, 9, 15, 18])\n",
    "k_probs = torch.tensor([0.133, 0.6, 0.133, 0.133])\n",
    "\n",
    "# -----------------------------\n",
    "# 9Ô∏è‚É£ Create train/val splits\n",
    "# -----------------------------\n",
    "dataset = TensorDataset(X_data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# üîü Initialize model + optimizer\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loc_mask_base = loc_mask_base.to(device)\n",
    "train_coords_y = train_coords_y.to(device)\n",
    "train_coords_x = train_coords_x.to(device)\n",
    "valid_coords = valid_coords.to(device)\n",
    "k_choices = k_choices.to(device)\n",
    "k_probs = k_probs.to(device)\n",
    "X_data = X_data.to(device)\n",
    "\n",
    "hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "model = ConditionalVAE(\n",
    "    in_channels=1,\n",
    "    loc_channels=2,\n",
    "    mask_channels=1,\n",
    "    latent_dim=16,\n",
    "    img_size=H,\n",
    "    hidden_dims=hidden_dims,\n",
    "    coord_decode=True\n",
    ").to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 50\n",
    "kld_weight = 1e-3\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Training Loop\n",
    "# -----------------------------\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for (x_batch,) in tqdm(train_loader, leave=False):\n",
    "        x_batch = x_batch.to(device)\n",
    "        batch_size = x_batch.size(0)\n",
    "\n",
    "        loc_batch = loc_mask_base.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "        # Sample k points\n",
    "        k_samples_indices = torch.multinomial(k_probs, num_samples=batch_size, replacement=True)\n",
    "        k_values = k_choices[k_samples_indices]\n",
    "\n",
    "        mask_batch = torch.zeros(batch_size, 1, H, W, device=device)\n",
    "        for i in range(batch_size):\n",
    "            k = k_values[i].item()\n",
    "            indices_to_pick = torch.randperm(num_train_locs, device=device)[:k]\n",
    "            y = train_coords_y[indices_to_pick]\n",
    "            x = train_coords_x[indices_to_pick]\n",
    "            mask_batch[i, 0, y, x] = 1.0\n",
    "\n",
    "        x_input_batch = x_batch * mask_batch\n",
    "\n",
    "        mu_pred, logvar_pred, mu, log_var = model(\n",
    "            x_input_batch, loc_batch, mask_batch,\n",
    "            coords=valid_coords.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        )\n",
    "\n",
    "        losses = model.loss_function(\n",
    "            x_batch, mu_pred, logvar_pred, mu, log_var,\n",
    "            meas_mask=mask_batch, kld_weight=kld_weight\n",
    "        )\n",
    "        loss = losses[\"loss\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_mask_base = torch.zeros(1, 1, H, W, device=device)\n",
    "    # Define your validation coordinates (example: pick 9 points from train_coords)\n",
    "    val_coords_y = train_coords_y[:9]\n",
    "    val_coords_x = train_coords_x[:9]\n",
    "    val_mask_base[0, 0, val_coords_y, val_coords_x] = 1.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x_batch,) in val_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            batch_size = x_batch.size(0)\n",
    "            loc_batch = loc_mask_base.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "            mask_batch = val_mask_base.repeat(batch_size, 1, 1, 1)\n",
    "            x_input_batch = x_batch * mask_batch\n",
    "\n",
    "            mu_pred, logvar_pred, mu, log_var = model(\n",
    "                x_input_batch, loc_batch, mask_batch,\n",
    "                coords=valid_coords.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "            )\n",
    "            losses = model.loss_function(\n",
    "                x_batch, mu_pred, logvar_pred, mu, log_var,\n",
    "                meas_mask=mask_batch, kld_weight=kld_weight\n",
    "            )\n",
    "            val_loss += losses[\"loss\"].item() * x_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b28813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Pick a batch from validation set (or entire val_loader)\n",
    "    for (x_batch,) in val_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        batch_size = x_batch.size(0)\n",
    "        loc_batch = loc_mask_base.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "        mask_batch = val_mask_base.repeat(batch_size, 1, 1, 1)\n",
    "        x_input_batch = x_batch * mask_batch\n",
    "\n",
    "        # Predict at valid coordinates\n",
    "        mu_pred, logvar_pred, _, _ = model(\n",
    "            x_input_batch, loc_batch, mask_batch,\n",
    "            coords=valid_coords.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        )\n",
    "\n",
    "        # mu_pred: predicted mean at valid coordinates\n",
    "        # logvar_pred: predicted log-variance at valid coordinates\n",
    "        pred_mean = mu_pred.cpu()\n",
    "        pred_std = torch.exp(0.5 * logvar_pred).cpu()\n",
    "        break  # take only first batch for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_coords: (num_valid, 2)\n",
    "pred_grid = torch.zeros((batch_size, H, W))\n",
    "for i in range(batch_size):\n",
    "    y_coords = valid_coords[:,0]\n",
    "    x_coords = valid_coords[:,1]\n",
    "    pred_grid[i, y_coords, x_coords] = pred_mean[i, 0, :, :].flatten()  # flatten if needed\n",
    "\n",
    "# Inverse normalization\n",
    "pred_grid_real = pred_grid * (global_normalization_std + 1e-6) + global_normalization_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342dfe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i in range(batch_size):\n",
    "    y_coords = train_coords_y  # measured points\n",
    "    x_coords = train_coords_x\n",
    "    y_coords_val = val_coords_y  # use validation measured points if desired\n",
    "    x_coords_val = val_coords_x\n",
    "\n",
    "    # Ground truth\n",
    "    gt = X_data[i,0,y_coords,x_coords].cpu() * (global_normalization_std + 1e-6) + global_normalization_mean\n",
    "    # Prediction\n",
    "    pred = pred_grid_real[i, y_coords, x_coords]\n",
    "\n",
    "    mse = mean_squared_error(gt, pred)\n",
    "    mae = mean_absolute_error(gt, pred)\n",
    "    r2 = r2_score(gt, pred)\n",
    "    metrics.append((mse, mae, r2))\n",
    "\n",
    "avg_mse = np.mean([m[0] for m in metrics])\n",
    "avg_mae = np.mean([m[1] for m in metrics])\n",
    "avg_r2 = np.mean([m[2] for m in metrics])\n",
    "\n",
    "print(f\"Validation Metrics (measured points only):\")\n",
    "print(f\"  MSE: {avg_mse:.4f}, MAE: {avg_mae:.4f}, R¬≤: {avg_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e186a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(pred_grid_real[0].numpy(), origin='lower', cmap='viridis')\n",
    "plt.scatter(train_coords_x.cpu(), train_coords_y.cpu(), color='red', marker='x', label='Measured sensors')\n",
    "plt.colorbar(label='SINR (dB)')\n",
    "plt.legend()\n",
    "plt.title('Predicted SINR map (sample 0)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ Set model to eval\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "batch_size = X_data.size(0)\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ Prepare location + measurement masks\n",
    "# -----------------------------\n",
    "loc_batch = loc_mask_base.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "# Use all measured points as mask for evaluation\n",
    "eval_mask = torch.zeros(batch_size, 1, H, W, device=device)\n",
    "for i in range(batch_size):\n",
    "    eval_mask[i, 0, train_coords_y, train_coords_x] = 1.0\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ Forward pass to predict at valid coordinates\n",
    "# -----------------------------\n",
    "with torch.no_grad():\n",
    "    mu_pred, logvar_pred, _, _ = model(\n",
    "        X_data * eval_mask,\n",
    "        loc_batch,\n",
    "        eval_mask,\n",
    "        coords=valid_coords.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ Convert predictions to original scale\n",
    "# -----------------------------\n",
    "# mu_pred shape: (batch_size, 1, num_valid)\n",
    "mu_pred = mu_pred.squeeze(1)  # (batch_size, num_valid)\n",
    "pred_sinr = mu_pred * global_normalization_std + global_normalization_mean  # inverse normalization\n",
    "\n",
    "# Optional: std/uncertainty\n",
    "std_pred = torch.exp(0.5 * logvar_pred.squeeze(1)) * global_normalization_std\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ Compute metrics at measured points\n",
    "# -----------------------------\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Gather ground truth at valid_coords for comparison\n",
    "y_vals = valid_coords[:, 0]\n",
    "x_vals = valid_coords[:, 1]\n",
    "\n",
    "true_vals = torch.zeros(batch_size, len(valid_coords), device=device)\n",
    "for i in range(batch_size):\n",
    "    true_vals[i] = X_data[i, 0, y_vals, x_vals] * global_normalization_std + global_normalization_mean\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(true_vals.cpu().numpy().flatten(), pred_sinr.cpu().numpy().flatten())\n",
    "mae = mean_absolute_error(true_vals.cpu().numpy().flatten(), pred_sinr.cpu().numpy().flatten())\n",
    "print(f\"Evaluation Metrics | MSE: {mse:.4f} | MAE: {mae:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ Visualize predictions vs ground truth (example for first sample)\n",
    "# -----------------------------\n",
    "sample_idx = 0\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x_vals.cpu(), y_vals.cpu(), c=true_vals[sample_idx].cpu(), cmap='viridis', s=60)\n",
    "plt.colorbar(label='Ground truth SINR')\n",
    "plt.title('Ground truth SINR at valid coordinates')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x_vals.cpu(), y_vals.cpu(), c=pred_sinr[sample_idx].cpu(), cmap='viridis', s=60)\n",
    "plt.colorbar(label='Predicted SINR')\n",
    "plt.title('Predicted SINR at valid coordinates')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ Optional: Visualize uncertainty\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(x_vals.cpu(), y_vals.cpu(), c=std_pred[sample_idx].cpu(), cmap='inferno', s=60)\n",
    "plt.colorbar(label='Predicted std (uncertainty)')\n",
    "plt.title('Prediction Uncertainty at valid coordinates')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
